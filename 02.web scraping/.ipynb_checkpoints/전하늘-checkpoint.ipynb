{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "140681c8-7175-4914-b0c1-2a1d40bc769b",
   "metadata": {},
   "source": [
    "# 1. 네이버 날씨 정보 스크래핑 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a87a8bad-01f7-4e48-bfce-0c1b63222356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================\n",
      "날씨 확인 프로그램\n",
      "=====================================\n",
      "접속시간: 2023-11-06 15:21:33.370824\n",
      "접속위치: 마포구 합정동\n",
      "---------------------------\n",
      "1. 현재 날씨 및 온도 확인\n",
      "2. 최저/최고 온도 확인\n",
      "3. 미세먼지 확인\n",
      "0. 종료\n",
      "---------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "번호를 입력하세요. 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================\n",
      "최저/최고 기온 확인\n",
      "=====================================\n",
      "---------------------------\n",
      "최저기온: 16°\n",
      "최고기온: 16°\n",
      "---------------------------\n",
      "=====================================\n",
      "날씨 확인 프로그램\n",
      "=====================================\n",
      "접속시간: 2023-11-06 15:21:39.664139\n",
      "접속위치: 마포구 합정동\n",
      "---------------------------\n",
      "1. 현재 날씨 및 온도 확인\n",
      "2. 최저/최고 온도 확인\n",
      "3. 미세먼지 확인\n",
      "0. 종료\n",
      "---------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "번호를 입력하세요. 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================\n",
      "미세먼지 확인\n",
      "=====================================\n",
      "---------------------------\n",
      "좋음\n",
      "---------------------------\n",
      "=====================================\n",
      "날씨 확인 프로그램\n",
      "=====================================\n",
      "접속시간: 2023-11-06 15:21:42.243611\n",
      "접속위치: 마포구 합정동\n",
      "---------------------------\n",
      "1. 현재 날씨 및 온도 확인\n",
      "2. 최저/최고 온도 확인\n",
      "3. 미세먼지 확인\n",
      "0. 종료\n",
      "---------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "번호를 입력하세요. 0\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import datetime\n",
    "\n",
    "res = requests.get('https://search.naver.com/search.naver?query=날씨')\n",
    "soup = BeautifulSoup(res.text,'lxml')\n",
    "\n",
    "# 현재 위치\n",
    "location = soup.find('h2', attrs={'class':'blind'}).text\n",
    "\n",
    "# 1. 현재 날씨 및 온도\n",
    "present_weather = soup.find('span', attrs={'class':'weather before_slash'}).text\n",
    "ele =  soup.find('div', attrs={'class':'temperature_text'})\n",
    "present_thermo = ele.find('strong').text\n",
    "\n",
    "#2. 최고 최저 기온\n",
    "lowest_thermo = soup.find('span', attrs={'class':'lowest'})\n",
    "highest_thermo = soup.find('span', attrs={'class':'highest'})\n",
    "\n",
    "#3. 미세먼지 확인\n",
    "microdust = soup.find('span', attrs={'class':'txt'}).text\n",
    "\n",
    "while True:\n",
    "    print('=====================================')\n",
    "    print('날씨 확인 프로그램')\n",
    "    print('=====================================')\n",
    "    print('접속시간:', datetime.datetime.now())\n",
    "    print('접속위치:', location)\n",
    "    print('---------------------------')\n",
    "    print('1. 현재 날씨 및 온도 확인')\n",
    "    print('2. 최저/최고 온도 확인')\n",
    "    print('3. 미세먼지 확인')\n",
    "    print('0. 종료')\n",
    "    print('---------------------------')\n",
    "    user = input('번호를 입력하세요.')\n",
    "\n",
    "    if user == '0': break\n",
    "    elif user == '1':\n",
    "        print('=====================================')\n",
    "        print('현재 날씨 확인')\n",
    "        print('=====================================')\n",
    "        print('---------------------------')\n",
    "        print(present_weather, '/', present_thermo)\n",
    "        print('---------------------------')\n",
    "    elif user == '2':\n",
    "        print('=====================================')\n",
    "        print('최저/최고 기온 확인')\n",
    "        print('=====================================')\n",
    "        print('---------------------------')\n",
    "        print(f'{list(lowest_thermo.children)[0].text}: {list(lowest_thermo.children)[1].text}')\n",
    "        print(f'{list(highest_thermo.children)[0].text}: {list(highest_thermo.children)[1].text}')\n",
    "        print('---------------------------')\n",
    "    elif user == '3':\n",
    "        print('=====================================')\n",
    "        print('미세먼지 확인')\n",
    "        print('=====================================')\n",
    "        print('---------------------------')\n",
    "        print(microdust)\n",
    "        print('---------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69167247-067a-4f6e-81f5-88f0048e900a",
   "metadata": {},
   "source": [
    "# 2. 네이버에서 bts이미지를 검색한 후 나온 결과 중 10개의 이미지를 저장하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8f03786-09d5-4ea7-8117-354bed63d5db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1].https://search.pstatic.net/common/?src=http%3A%2F%2Fimgnews.naver.net%2Fimage%2F586%2F2023%2F08%2F28%2F0000063530_001_20230828130903586.jpg&type=sc960_832\n",
      "[2].https://search.pstatic.net/common/?src=http%3A%2F%2Fimgnews.naver.net%2Fimage%2F214%2F2023%2F09%2F20%2F0001301192_001_20230920185703428.jpg&type=sc960_832\n",
      "[3].https://search.pstatic.net/sunny/?src=https%3A%2F%2Fi.pinimg.com%2Foriginals%2Fb2%2F18%2F2f%2Fb2182fd22a3a6931be39f6c7e6a77bbf.jpg&type=sc960_832\n",
      "[4].https://search.pstatic.net/common/?src=http%3A%2F%2Fblogfiles.naver.net%2FMjAyMzA1MzFfMjQ1%2FMDAxNjg1NTI5NTAyOTk2.__HDO8RTot5eEWf8Y3MIn-1fI-gvIM5bQd231oFTaDMg.HKQ5zPkUCTHcJq2QwXTX0P82Lst_uw1mQCrIDIZTCVog.PNG.insertkn%2Fimage.png&type=sc960_832\n",
      "[5].https://search.pstatic.net/sunny/?src=https%3A%2F%2Fi.pinimg.com%2Foriginals%2Fef%2Ff0%2Ff7%2Feff0f718525bbbdc00992a691f1711b3.jpg&type=sc960_832\n",
      "[6].https://search.pstatic.net/common/?src=http%3A%2F%2Fimgnews.naver.net%2Fimage%2F020%2F2023%2F02%2F11%2F0003479072_001_20230211030147673.jpg&type=sc960_832\n",
      "[7].https://search.pstatic.net/sunny/?src=https%3A%2F%2Fi.pinimg.com%2Foriginals%2F8e%2F82%2Fcd%2F8e82cd8b649d0bbf52dd9cfeb68dd415.jpg&type=sc960_832\n",
      "[8].https://search.pstatic.net/sunny/?src=https%3A%2F%2Fi.pinimg.com%2Foriginals%2F52%2F7c%2F53%2F527c5331ae3faa26412e61f856153030.jpg&type=sc960_832\n",
      "[9].https://search.pstatic.net/sunny/?src=https%3A%2F%2Fi.pinimg.com%2Foriginals%2F67%2Fea%2F34%2F67ea3401653ca90a15e5eb01e1889785.jpg&type=sc960_832\n",
      "[10].https://search.pstatic.net/common/?src=http%3A%2F%2Fimgnews.naver.net%2Fimage%2F023%2F2023%2F09%2F26%2F0003790074_001_20230926043401064.jpg&type=sc960_832\n",
      "저장완료\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "\n",
    "IMAGE_EXTRACT_NUM = 10 \n",
    "SEARCH_KEYWORD = 'bts'\n",
    "\n",
    "# 1. 네이버 홈페이지 요청\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=webdriver.ChromeOptions())\n",
    "driver.get('https://www.naver.com/')\n",
    "\n",
    "# 2. 검색필드에 'bts' 검색\n",
    "ele = driver.find_element(By.ID, 'query')\n",
    "ele.send_keys('bts')\n",
    "ele.submit()\n",
    "\n",
    "# 3. 이미지 검색 결과 선택\n",
    "time.sleep(2)\n",
    "driver.find_element(By.CSS_SELECTOR, '#lnb > div.lnb_group > div > div.lnb_nav_area._nav_area_root > div > div.api_flicking_wrap._conveyer_root > div:nth-child(1)').click()\n",
    "time.sleep(2)\n",
    "\n",
    "# 4. 최초 검색된 이미지 10개 저장\n",
    "imgs = driver.find_elements(By.CSS_SELECTOR, '#main_pack > section.sc_new.sp_nimage._fe_image_viewer_prepend_target > div.api_subject_bx._fe_image_tab_list_root.ani_fadein > div > div > div.image_tile._fe_image_tab_grid > div > div > div > a')\n",
    "\n",
    "img_cnt  = 0\n",
    "img_src_list = []\n",
    "for img in imgs:\n",
    "    img.click()\n",
    "    try:\n",
    "        img_src = driver.find_element(By.XPATH, '//*[@id=\"main_pack\"]/section[1]/div/div/div[1]/div[2]/div[1]/img').get_attribute('src')\n",
    "    except: continue\n",
    "\n",
    "    if not img_src.startswith('http'):\n",
    "        continue\n",
    "        \n",
    "    img_cnt += 1\n",
    "    print(f'[{img_cnt}].{img_src}')\n",
    "    img_src_list.append(img_src)\n",
    "    \n",
    "    if img_cnt == IMAGE_EXTRACT_NUM: break\n",
    "\n",
    "# 5. 이미지 저장하기\n",
    "import os \n",
    "import requests\n",
    "\n",
    "path = 'c:/Temp/' \n",
    "\n",
    "os.chdir(path)  \n",
    "if not os.path.exists('bts_imgs'):   \n",
    "    os.makedirs('bts_imgs')\n",
    "\n",
    "file_no = 1\n",
    "os.chdir(path+'bts_imgs') \n",
    "for url in img_src_list:\n",
    "    extension = url.split('.')[-1]  \n",
    "    ext = ''\n",
    "    if extension in ['jpg','JPG','jpeg','JPEG','png','PNG','gif','GIF']: \n",
    "        ext = '.'+extension\n",
    "    else: \n",
    "        ext = '.jpg'\n",
    "\n",
    "    file_name = str(file_no)+'-'+SEARCH_KEYWORD+ext \n",
    "\n",
    "    file_no += 1\n",
    "    res = requests.get(url)\n",
    "    with open(file_name, 'wb') as f:\n",
    "        f.write(res.content)     \n",
    "        \n",
    "print('저장완료')\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8499ce8a-6541-4111-8989-49927efb41ed",
   "metadata": {},
   "source": [
    "# 3. 멜론 사이트 최신곡 검색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a1535ebd-ae70-493f-8663-fb26ac651d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] ESPRESSO MARTINI | 알리 (ALi) | ESPRESSO MARTINI\n",
      "[2] Brachio | 다린 | Brachio\n",
      "[3] 나쁜여자 | 김나희 | 나쁜여자\n",
      "[4] Start To Shine (feat.개코) | 규빈 | Start To Shine (feat.개코)\n",
      "[5] 왜 이래(Feat. SURAN(수란)) | HAAN | 한준한줌\n",
      "[6] 딥하게 (DEEP IN LOVE) | 멋진녀석들 (GreatGuys) | 靑春記錄  第2話 : 深\n",
      "[7] 너의 계절이 돌아올거야 | 로시 (Rothy) | 너의 계절이 돌아올거야\n",
      "[8] 어디까지 간 거야 | Chan (찬) | 어디까지 간 거야\n",
      "[9] 사랑하게 됐나 봐 | 안예슬 | 사랑하게 됐나 봐\n",
      "[10] 키치죠지의 검은 고양이 | 박근홍 | 키치죠지의 검은 고양이\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=webdriver.ChromeOptions())\n",
    "driver.get('https://www.melon.com/new/index.htm')\n",
    "soup = BeautifulSoup(driver.page_source, 'lxml')\n",
    "\n",
    "# 웹페이지에서 제목명 태그, 가수명 태그, 앨범명 태그 가져오기 \n",
    "song_chart = soup.find('tbody')\n",
    "song_titles = song_chart.find_all('div', attrs={'class':'ellipsis rank01'})\n",
    "song_artists = song_chart.find_all('div', attrs={'class':'ellipsis rank02'})\n",
    "song_albums = song_chart.find_all('div', attrs={'class':'ellipsis rank03'})\n",
    "\n",
    "title_list=[]\n",
    "artist_list=[]\n",
    "album_list=[]\n",
    "for title in song_titles:\n",
    "    title = title.find('a')\n",
    "    title_list.append(title.text)\n",
    "for artist in song_artists:\n",
    "    artist_list.append(list(artist.children)[1].text)\n",
    "for album in song_albums:\n",
    "    album = album.find('a')\n",
    "    album_list.append(album.text)\n",
    "\n",
    "for i in range(10):\n",
    "    print(f'[{i+1}] {title_list[i]} | {artist_list[i]} | {album_list[i]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02345a3-1a9e-4b17-bdc3-2fab60e26c0d",
   "metadata": {},
   "source": [
    "# 4. 대문자 시작 단어 찾기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9698d478-4be7-4486-adee-4418e8af19b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Edit', 'Expression', 'Text', 'Roll', 'PCRE', 'JavaScript', 'RegEx', 'Validate', 'Tests']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "s = 'Edit the Expression & Text to see matches. Roll over matches or the expression for details. PCRE & JavaScript flavors of RegEx are supported. Validate your expression with Tests mode.'\n",
    "\n",
    "p = re.compile('[A-Z]+[a-z]*[A-Z]*[a-z]*')\n",
    "print(p.findall(s))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93703ec1-1885-4717-ac55-a91b1ca283cc",
   "metadata": {},
   "source": [
    "# 5. 이메일 주소 추출하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e534d0fd-af89-44af-9656-6bf20eb64bcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['john.d@yahoo.com', 'ryan.arjun@gmail.com', 'rosy.gray@amazon.co.uk']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "s = 'Ryan has sent an invoice email to john.d@yahoo.com by using his email id ryan.arjun@gmail.com and he also shared a copy to his boss rosy.gray@amazon.co.uk on the cc part.'\n",
    "\n",
    "p = re.compile('[a-zA-Z]+[.]?\\w*[@][a-z]+[.][a-z]+[.]?[a-z]*')\n",
    "print(p.findall(s))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
